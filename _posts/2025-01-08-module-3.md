---
title: "Module 3: Retrieval-Augmented Generation"
layout: post
---

In this module, we'll explore how language models can be enhanced by connecting them to external sources of information—a technique known as Retrieval-Augmented Generation (RAG). While LLMs are powerful, they're limited to the data they were trained on. RAG allows the model to retrieve external content in real time and use it as context for generating more accurate and relevant responses.


<div style="display: block; text-align: center; line-height: 0;">

  <img src="{{ '/assets/images/langchain_indexing.png' | relative_url }}" alt="Langchain Indexing" 
       style="width: 80%; height: auto; border-radius: 8px; display: block; margin: 0 auto;" />

  <img src="{{ '/assets/images/langchain_retrieval.png' | relative_url }}" alt="Langchain Retrieval" 
       style="width: 80%; height: auto; border-radius: 8px; display: block; margin: 0 auto;" />

</div>
*Image source: [LangChain Documentation](https://python.langchain.com/docs/tutorials/rag/)*

To build a RAG system, we'll cover the full pipeline: loading data from various sources, splitting long texts into chunks, embedding the content into vectors, storing it in vector databases, retrieving the most relevant pieces during a query, and finally using that retrieved information to generate informed answers.

<div style="display: flex; gap: 20px; justify-content: center; flex-wrap: nowrap;">

  <iframe style="width: calc(50% - 10px); aspect-ratio: 16 / 9; border: none;" 
          src="https://www.youtube.com/embed/T-D1OfcDW1M" 
          title="YouTube video player" 
          allowfullscreen>
  </iframe>

  <iframe style="width: calc(50% - 10px); aspect-ratio: 16 / 9; border: none;" 
          src="https://www.youtube.com/embed/zYGDpG-pTho" 
          title="YouTube video player" 
          allowfullscreen>
  </iframe>

</div>

Before we begin exploring each topic individually, here's a brief overview of the core components involved in the Retrieval-Augmented Generation (RAG) workflow. Each step plays a crucial role in enabling language models to retrieve and use external information effectively:

* **Document Loaders**: Responsible for bringing external data into the system. They support a wide variety of formats such as PDFs, web pages, databases, and cloud files, acting as the entry point to your knowledge base.

* **Text Splitters**: Once documents are loaded, they are broken down into smaller, more manageable chunks. This helps ensure that information remains coherent and accessible during processing and retrieval.

* **Text Embedding Models**: These models convert chunks of text into numerical vectors that capture the meaning and context of the content. This transformation enables semantic search, where similar concepts are positioned closely in vector space.

* **Vector Stores**: Specialized databases that store and organize text embeddings. They allow for fast and meaningful retrieval of content and are compatible with in-memory setups or scalable cloud-based solutions.

* **Retrievers**: Tools that search the vector store to find the most relevant pieces of information based on a user query. Different types of retrievers exist, from simple semantic matchers to more advanced ones like self-query retrievers or ensemble approaches that combine multiple strategies.

* **Generation**: Finally, the language model takes the retrieved context and uses it to generate responses that are more accurate, grounded, and relevant to the query.

*The video below offers a high-level overview of the key topics we’ll be working on in this module. It serves as a helpful preview of what’s to come, and each component will be explored individually and in more depth as we move forward.*

{% include embed.html url="https://www.youtube.com/embed/tcqEUSNCn8I" %}

---

# **1. Document Loaders**

Document Loaders are responsible for bringing external content—like CSVs, PDFs, web pages, and databases—into your application in a format that LangChain can work with. Regardless of the source, all loaders return data in a unified structure called a `Document`, which includes both the content and relevant metadata.

Each type of loader is designed to handle a specific format or data source, and while their configuration parameters vary depending on the integration, they all share a common interface: you initialize the loader and call its `.load()` method to extract the data.

```python
# Load CSV file
from langchain_community.document_loaders.csv_loader import CSVLoader

loader = CSVLoader( 
    ...  # Your custom parameters here
)
documents = loader.load()
```

```python
# Load PDF file
from langchain_community.document_loaders import PyPDFLoader

file_path = "./example_data/layout-parser-paper.pdf"
loader = PyPDFLoader(file_path)

documents = loader.load()
```

<div style="display: flex; align-items: flex-start; gap: 20px;">
  
  <div style="flex: 0 0 25%;">
    <a href="https://python.langchain.com/docs/integrations/document_loaders/" target="_blank">
      <img src="{{ '/assets/images/lc_document_loaders.png' | relative_url }}" alt="Langchain Document Loaders"
           style="width: 100%; height: auto; border-radius: 8px;" />
    </a>
  </div>
  
  <div style="flex: 1;">
    <p>
      <em>
        This allows you to work with structured data in a consistent way, no matter where it came from. LangChain provides many such loaders to make it easy to connect your AI workflows to real-world data.
      </em>
    </p>
  </div>

</div>