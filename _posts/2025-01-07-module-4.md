---
title: "Module 4: RAG - Retrieval and Generation: Enhancing Language Models with Context-Aware Retrieval and Generation"
layout: post
--- 

In this module, we dive into the second core stage of the RAG pipeline: Retrieval and Generation. This is where things start to come together — we'll retrieve relevant chunks of information from our vector database and use them to generate accurate, context-aware responses through language models. By the end of this module, you'll be able to implement a fully functional RAG flow that brings your documents to life with intelligent answers.


In the previous module, we focused on the indexing process, laying the groundwork by exploring key components such as Document Loaders, Text Splitters, Embedding Models, and Vector Stores. Now, it's time to leverage all that structure to build an end-to-end RAG solution.

> **Let's quickly recap what Retrieval-Augmented Generation is all about:**
>
> RAG is a technique that enhances the capabilities of language models by integrating them with external sources of information. Rather than relying solely on their internal training data — which can become outdated or limited — RAG systems dynamically fetch relevant content from a knowledge base at query time.
>
> When a user makes a request, the system first retrieves the most relevant documents or data segments. This retrieved context is then passed along to the language model, enriching its prompt and allowing it to generate responses that are more accurate, up-to-date, and grounded in real information. By combining retrieval with generation, RAG bridges the gap between static knowledge and dynamic understanding — making AI systems significantly more useful and reliable in real-world applications.

---

# **1. Retrieve**

<div style="display: block; text-align: center;">

  <img src="{{ '/assets/images/lc_retrieval.jpg' | relative_url }}" alt="Langchain Pipeline Retrieval" 
       style="width: 100%; height: auto; border-radius: 8px; display: block; margin: 0 auto;" />

</div>

*Image source: [LangChain Documentation](https://python.langchain.com/v0.1/docs/modules/data_connection/)*

Now that you understand the big picture of Retrieval-Augmented Generation, it's time to dive deeper into one of its core components: Retrieval.

Large Language Models are incredibly powerful, but they have one major limitation — their knowledge is frozen at the time of training. This makes it difficult for them to answer questions about recent events or provide accurate details in niche domains. While fine-tuning or continued pretraining are possible ways to inject new knowledge, these approaches are often costly, slow, and still not ideal for retrieving specific, up-to-date facts.

**This is where retrieval systems come in:**

> By connecting your LLM to a retrieval system, you enable it to access relevant external information at the time of the query. This makes your AI not only more context-aware, but also driven by the information you feed into it.

Here's a simple example of how the retrieval step works in a RAG pipeline.
We start with a user question, use a retriever to find relevant context from a knowledge base, and then pass that information into a language model. The model uses this retrieved context to generate a grounded and relevant answer.

```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

# Define a system prompt that tells the model how to use the retrieved context
system_prompt = """You are an assistant for question-answering tasks. 
Use the following pieces of retrieved context to answer the question. 
If you don't know the answer, just say that you don't know. 
Context: {context}:"""
    
# Define a question
question = """What event did Dandilyonn organize to support the Climate Reality Project?""""

# Retrieve relevant documents
docs = retriever.invoke(question)

# Combine the documents into a single string
docs_text = "".join(d.page_content for d in docs)

# Populate the system prompt with the retrieved context
system_prompt_fmt = system_prompt.format(context=docs_text)

# Create a model
model = ChatOpenAI(model="gpt-4o", temperature=0) 

# Generate a response
questions = model.invoke([SystemMessage(content=system_prompt_fmt),
                          HumanMessage(content=question)])
```

*Here's what the full retrieval and generation flow looks like in practice — from question to context retrieval to a generated answer, all working together to deliver informed responses.*

**Question:**
> What event did Dandilyonn organize to support the Climate Reality Project?

**Retrieved Context:**
> "To fundraise for Al Gore's Climate Reality Project, Dandilyonn hosted our first ever walkathon. In addition to raising funds, it was a statement that the Dandilyonn Community will never stand down in this fight against climate change."

**Generated Answer:**
> Dandilyonn organized its first-ever walkathon to raise funds for Al Gore's Climate Reality Project and to show its commitment to fighting climate change.

*Reference: [LangChain Concepts](https://python.langchain.com/docs/concepts/rag/)*


## Understanding Retrieval in LangChain

In this course, we focus specifically on retrieving documents through similarity search in vector databases, particularly using Pinecone. This means we embed both documents and user queries as vectors and search for the most similar ones to return relevant information. This approach is very efficient for handling unstructured text data like articles, notes, and PDF content.

However, it’s important to understand that retrieval in AI applications is a broader concept, and LangChain provides a unified interface that supports many different types of retrievers beyond just vector stores. If you're curious and want to explore the wide range of possibilities, I encourage you to read the official LangChain documentation:

<div style="display: flex; gap: 20px; justify-content: center; flex-wrap: wrap;">

  <a href="https://python.langchain.com/docs/concepts/retrievers/" target="_blank" style="flex: 1 1 22%; box-sizing: border-box;">
    <img src="{{ '/assets/images/lc_retrievers.png' | relative_url }}" alt="Retriever Overview"
         style="width: 100%; height: auto; border-radius: 8px;" />
  </a>

  <a href="https://python.langchain.com/docs/concepts/retrieval/" target="_blank" style="flex: 1 1 22%; box-sizing: border-box;">
    <img src="{{ '/assets/images/lc_retrieval.png' | relative_url }}" alt="Retrieval Concept"
         style="width: 100%; height: auto; border-radius: 8px;" />
  </a>

</div>

## What Other Retrieval Methods Exist?

Besides vector stores, retrievers in LangChain can be built on top of:

> Search APIs like Wikipedia or Amazon Kendra
> Lexical search indexes such as BM25 and TF-IDF
> Relational databases (e.g., SQL via Text-to-SQL transformation)
> Graph databases (e.g., Cypher via Text-to-Cypher transformation)

Each of these has a different use case. For example:

> Lexical search works by matching exact words in queries and documents.
> SQL and graph retrievers require structured data and can benefit from natural language-to-query transformations.
> Hybrid and ensemble retrievers combine multiple strategies (e.g., BM25 + vector search).
> Advanced Query Handling

Modern retrieval techniques often use language models to optimize the search process. These enhancements include:

> Query rewriting to improve poorly worded user inputs.
> Query decomposition to break down complex questions.
> Step-back prompting to generalize and refocus a question.
> HyDE (Hypothetical Document Embeddings) for better recall.

*These methods are useful especially in complex applications, where the original query may not directly match the content of the documents.*

---

# **2. Generate**

---

<div style="display: flex; align-items: flex-start; gap: 20px;">
  
  <div style="flex: 0 0 25%;">
    <a href="https://cameronrwolfe.substack.com/p/a-practitioners-guide-to-retrieval?utm_source=profile&utm_medium=reader2" target="_blank">
      <img src="{{ '/assets/images/rag_advanced.png' | relative_url }}" alt="Rag Article"
           style="width: 100%; height: auto; border-radius: 8px;" />
    </a>
  </div>
  
  <div style="flex: 1;">
    <p>
      <em>
        For those who want to go beyond the basics and gain a deeper understanding of how Retrieval-Augmented Generation truly works, I highly recommend reading A Practitioner's Guide to RAG by Cameron R. Wolfe, Ph.D. This article goes beyond simple tutorials and explores RAG from a practical, yet technically insightful perspective — covering foundational concepts, pipeline structure, chunking strategies, hybrid search, prompt design, evaluation methods, and even performance tuning. It's an excellent resource to understand not just how to implement RAG, but also why certain design decisions matter when building scalable, trustworthy AI systems.
      </em>
    </p>
  </div>

</div>